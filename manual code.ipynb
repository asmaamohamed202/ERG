{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7925900,"sourceType":"datasetVersion","datasetId":4658129},{"sourceId":7929239,"sourceType":"datasetVersion","datasetId":4660422}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"## importing Libraries ","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:07:25.746481Z","iopub.execute_input":"2024-05-19T19:07:25.747306Z","iopub.status.idle":"2024-05-19T19:07:25.751421Z","shell.execute_reply.started":"2024-05-19T19:07:25.747275Z","shell.execute_reply":"2024-05-19T19:07:25.750380Z"}}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import array_to_img, img_to_array, load_img","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:04.803880Z","iopub.execute_input":"2024-05-19T19:12:04.804255Z","iopub.status.idle":"2024-05-19T19:12:04.808957Z","shell.execute_reply.started":"2024-05-19T19:12:04.804226Z","shell.execute_reply":"2024-05-19T19:12:04.808076Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport pywt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:07.849380Z","iopub.execute_input":"2024-05-19T19:12:07.850124Z","iopub.status.idle":"2024-05-19T19:12:07.855072Z","shell.execute_reply.started":"2024-05-19T19:12:07.850088Z","shell.execute_reply":"2024-05-19T19:12:07.854043Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## importing our dataset (ERG) ","metadata":{}},{"cell_type":"code","source":"# Read the Excel file into a Pandas DataFrame\nSR = pd.read_excel(\"/kaggle/input/electroretinogram/01 Appendix 1.xlsx\", sheet_name='Scotopic 2.0 ERG Response')\nPR = pd.read_excel(\"/kaggle/input/electroretinogram/01 Appendix 1.xlsx\", sheet_name='Photopic 2.0 ERG Response')\nMR = pd.read_excel(\"/kaggle/input/electroretinogram/01 Appendix 1.xlsx\", sheet_name='Maximum 2.0 ERG Response')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:11.915228Z","iopub.execute_input":"2024-05-19T19:12:11.916080Z","iopub.status.idle":"2024-05-19T19:12:18.934766Z","shell.execute_reply.started":"2024-05-19T19:12:11.916045Z","shell.execute_reply":"2024-05-19T19:12:18.933727Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Sparkline Group extension is not supported and will be removed\n  warn(msg)\n/opt/conda/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Sparkline Group extension is not supported and will be removed\n  warn(msg)\n/opt/conda/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Sparkline Group extension is not supported and will be removed\n  warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"MR.drop(columns = MR.columns[124:], inplace=True)\nPR.drop(columns = PR.columns[110:], inplace=True)\nSR.drop(columns = SR.columns[80:], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:18.936488Z","iopub.execute_input":"2024-05-19T19:12:18.936833Z","iopub.status.idle":"2024-05-19T19:12:18.970128Z","shell.execute_reply.started":"2024-05-19T19:12:18.936804Z","shell.execute_reply":"2024-05-19T19:12:18.969203Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"mapping = {'The functional activity of the central and peripheral parts of the retina in both eyes is preserved.':'abnormal','Pupil is narrow.':'abnormal','The functional activity of the central and peripheral parts of the retina in both eyes is preserved.':'abnormal','Registration of ERG with a narrow pupil.':'abnormal','Registration of the ERG of a narrow pupil from the skin of the eyelid.':'abnormal','ERG pupil is narrow.':'abnormal','Registration of ERG from the skin of the eyelid, the pupil is narrow.':'abnormal','Registration of ERG with a narrow pupil from the skin of the eyelid.':'abnormal','The functional activity of the central and peripheral parts of the retina in both eyes is preserved.':'abnormal','High level of interference due to increased physical activity of the child.':'abnormal','The functional activity of the retina is preserved.':'normal','The functional activity of the retina at the OU is preserved.': 'normal','The functional activity of the retina is preserved.':'normal','No negative dynamics compared to previous data.': 'normal','The functional activity of the retina is preserved.': 'normal','The functional activity of the central and peripheral parts of the retina in both eyes is preserved.':'normal','No diagnosis.': 'normal','The signal is within normal limits.': 'normal','The functional activity of the retina is preserved, corresponds to the age norm symmetrically on the OU.': 'normal','The functional activity of the retina in both eyes is preserved.': 'normal','The amplitude-time characteristics of the EP in a homogeneous field correspond to the norm.': 'normal','The functional activity of the retina in both eyes is preserved. High level of interference due to increased motor activity of the child.': 'normal','The functional activity of the retina at the OU is preserved. No macular pathology was revealed.': 'The functional activity of the central and peripheral parts of the retina in both eyes is preserved.','No diagnosis.': 'normal','Electrogenesis of the central parts of the retina normally does not exclude dystrophy of the rod apparatus of the retina with a favorable prognosis of the course.': 'normal','The functional activity of the central and peripheral parts of the retina in both eyes is preserved.':'normal','Correct configuration potentials. The amplitude-time characteristics of the a- and b-waves of the rod maximal and cone responses correspond to the norm.': 'normal', 'Perhaps the reason for the violation of twilight vision is hypovitaminosis.': 'normal' ,'Hereditary cone dystrophy.': 'abnormal', \n          'Retinal rod dystrophy with a favorable prognosis is not excluded.': 'abnormal','Decreased the amplitude of the b-wave of the maximum and rod responses.': 'abnormal','Electrogenesis of the peripheral parts of the retina in the norm, the electrogenesis of the central parts of the retina is sharply impaired. Perhaps there is hereditary cone dystrophy.': 'abnormal','Reduced functional activity of the retina changes at the level of the outer and middle layers in the central and peripheral parts.': 'abnormal','Combination of congenital myopia and congenital hemeralopia.': 'abnormal','OD - outside and in the upper section of the old chorioretinal focus.': 'abnormal','Rod dystrophy of the retina with a favorable prognosis.': 'abnormal','The functional activity of the peripheral parts of the retina is normal, the functional activity of the central parts of the retina is moderately reduced.': 'abnormal','Hereditary rod dystrophy of the retina is possible.': 'abnormal','Central dystrophy with cone-rod dysfunction is possible.': 'abnormal','The preservation of the retinal electrogenesis from its central and peripheral parts, as well as the preservation of conductivity along the pathways of the visual analyzer, can be expected to improve visual functions after restoration of the transparency of the OS optical media.': 'abnormal','Retinal cone-rod dystrophy.': 'abnormal', 'Pronounced organic changes in the outer and inner layers in the center and periphery of the retina.': 'abnormal', 'Moderate pronounced change in the outer and middle layers of the central and peripheral parts of the retina of the right eye.': 'abnormal', 'Decrease in electrogenesis and functional activity of the retina.': 'abnormal', 'Retinal rod dystrophy with a favorable prognosis is possible.': 'abnormal', 'Signs of moderate disturbances in the electrogenesis of the central parts of the retina in the left eye.': 'abnormal', 'OU - maximum ERG b-wave reduction. Central dystrophy with cone-rod dysfunction is possible.': 'abnormal', 'The functional activity of the retina of the left eye is protected by a moderate decrease in the functional activity of the retina of the right eye.': 'abnormal', 'The functional activity of the retina OD is preserved on the OS and is moderately reduced (changes at the level of the outer and middle layers of the retina in the central and peripheral regions).': 'abnormal', 'The functional activity of the central parts of the retina is moderately reduced.': 'abnormal', 'Changes in the bioelectrical activity of the retina against the background of high myopia.': 'abnormal', 'Hereditary rod dystrophy of the retina is not excluded.': 'abnormal', 'Decrease of the B-wave amplitude by 3 times on OD, 2 times on OS.': 'abnormal', 'OU - a pronounced decrease in the b-wave of the maximum response is reduced.': 'abnormal'}\nMR.replace(mapping, inplace=True)\nPR.replace(mapping, inplace=True)\nSR.replace(mapping, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:23.615669Z","iopub.execute_input":"2024-05-19T19:12:23.616000Z","iopub.status.idle":"2024-05-19T19:12:24.125055Z","shell.execute_reply.started":"2024-05-19T19:12:23.615976Z","shell.execute_reply":"2024-05-19T19:12:24.123995Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"patiant_Diagnosis_M = MR.iloc[4 , :122].tolist()\npatiant_Diagnosis_P = PR.iloc[4 , :106].tolist()\npatiant_Diagnosis_S = SR.iloc[4 , :74].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:27.279567Z","iopub.execute_input":"2024-05-19T19:12:27.280594Z","iopub.status.idle":"2024-05-19T19:12:27.286425Z","shell.execute_reply.started":"2024-05-19T19:12:27.280530Z","shell.execute_reply":"2024-05-19T19:12:27.285494Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"patiant_id_M = MR.iloc[3 , :122].tolist()\npatiant_id_P = PR.iloc[3 , :106].tolist() #20 \npatiant_id_S = SR.iloc[3 , :74].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:31.582741Z","iopub.execute_input":"2024-05-19T19:12:31.583739Z","iopub.status.idle":"2024-05-19T19:12:31.589738Z","shell.execute_reply.started":"2024-05-19T19:12:31.583700Z","shell.execute_reply":"2024-05-19T19:12:31.588591Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"M_R =['MR']*122\nP_R =['PR']*106\nS_R =['SR']*74","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:34.261075Z","iopub.execute_input":"2024-05-19T19:12:34.261780Z","iopub.status.idle":"2024-05-19T19:12:34.265987Z","shell.execute_reply.started":"2024-05-19T19:12:34.261750Z","shell.execute_reply":"2024-05-19T19:12:34.265017Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"len(patiant_Diagnosis_M+patiant_Diagnosis_P+patiant_Diagnosis_S)\nlen(patiant_id_P)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:36.466124Z","iopub.execute_input":"2024-05-19T19:12:36.467020Z","iopub.status.idle":"2024-05-19T19:12:36.473885Z","shell.execute_reply.started":"2024-05-19T19:12:36.466987Z","shell.execute_reply":"2024-05-19T19:12:36.472839Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"106"},"metadata":{}}]},{"cell_type":"code","source":"# Create a dictionary from the two lists\ndict = {'Patient_id': patiant_id_M+patiant_id_P+patiant_id_S, 'Label': patiant_Diagnosis_M+patiant_Diagnosis_P+patiant_Diagnosis_S ,'signal_type':M_R+P_R+S_R}\n\n# Create a new dataframe from the dictionary\ndf = pd.DataFrame(dict)\n#df=df.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:39.668437Z","iopub.execute_input":"2024-05-19T19:12:39.669279Z","iopub.status.idle":"2024-05-19T19:12:39.674453Z","shell.execute_reply.started":"2024-05-19T19:12:39.669246Z","shell.execute_reply":"2024-05-19T19:12:39.673591Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"filtered_df = df[df['Label'] == 'Diagnosis']","metadata":{"execution":{"iopub.status.busy":"2024-05-19T19:12:44.293310Z","iopub.execute_input":"2024-05-19T19:12:44.293700Z","iopub.status.idle":"2024-05-19T19:12:44.300845Z","shell.execute_reply.started":"2024-05-19T19:12:44.293671Z","shell.execute_reply":"2024-05-19T19:12:44.299946Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df = df[~(df['Label'] == 'Diagnosis')] #the negation operator ~ in front of the boolean mask, we invert the mask to select the rows that do not contain the specific value.\ndf=df.reset_index(drop=True)\ndf.groupby(['Label']).count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir signals\n!mkdir augmented_images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def repeat_val(x):\n    if x<200 : k=4 \n    elif x>200 and x<=400 : k=3 \n    elif x>400 and x<=550 : k=2 \n    return k  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transform the signal by Ricker wavelet (mexican hat)","metadata":{}},{"cell_type":"code","source":"signal_PR=[]\nsignal_PR_id=[]\npath='/kaggle/working/signals/'\nfor j in range(0,2):\n    for i in range (1,106):\n        signal = np.array(PR.iloc[21: ,i].tolist())\n        signal_values = signal[np.logical_not(np.isnan(signal))]\n        k = repeat_val(len(signal_values))\n\n        signal_values = np.tile(signal_values.tolist()+[0]*30,k-j)\n        \n        coefficients, frequencies = pywt.cwt(signal_values, scales=np.arange(1, 128), wavelet='mexh')\n        plt.figure(figsize=(5.12, 5.12))\n        plt.imshow(abs(coefficients) ** 2, cmap='gray', aspect='auto',vmax=abs(coefficients).max(), vmin=-abs(coefficients).min())\n        plt.axis('off')\n        plt.savefig(os.path.join(path, f'PR_{i}_{j}_f.png'))\n        plt.close()\n        signal_PR.append(path + f'PR_{i}_{j}_f.png')\n        signal_PR_id.append(f'PR_{i}_{j}_f')\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"signal_MR=[]\nsignal_MR_id=[]\nfor j in range(0,2):\n    for i in range (1,122):\n        signal = np.array(MR.iloc[22: ,i].tolist())  \n        signal_values = signal[np.logical_not(np.isnan(signal))]\n        k = repeat_val(len(signal_values))\n\n        signal_values = np.tile(signal_values.tolist()+[0]*30,k-j)\n        \n        coefficients, frequencies = pywt.cwt(signal_values, scales=np.arange(1, 128), wavelet='mexh')\n        plt.figure(figsize=(5.12, 5.12))\n        plt.imshow(abs(coefficients) ** 2, cmap='gray', aspect='auto',vmax=abs(coefficients).max(), vmin=-abs(coefficients).min())\n        plt.axis('off')\n        plt.savefig(os.path.join(path, f'MR_{i}_{j}_f.png'))\n        plt.close()\n        signal_MR.append(path + f'MR_{i}_{j}_f.png')\n        signal_MR_id.append(f'MR_{i}_{j}_f')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"signal_SR=[]\nsignal_SR_id=[]\nfor j in range(0,2):\n    for i in range (1,74):\n        signal = np.array(SR.iloc[21: ,i].tolist())  \n        signal_values = signal[np.logical_not(np.isnan(signal))]\n        k = repeat_val(len(signal_values))\n\n        signal_values = np.tile(signal_values.tolist()+[0]*0,k-j)\n          \n        coefficients, frequencies = pywt.cwt(signal_values, scales=np.arange(1, 128), wavelet='mexh')\n        plt.figure(figsize=(5.12, 5.12))\n        plt.imshow(abs(coefficients) ** 2, cmap='gray', aspect='auto',vmax=abs(coefficients).max(), vmin=-abs(coefficients).min())\n        plt.axis('off')\n        plt.savefig(os.path.join(path, f'SR_{i}_{j}_f.png'))\n        plt.close()\n        signal_SR.append(path + f'SR_{i}_{j}_f.png')\n        signal_SR_id.append(f'SR_{i}_{j}_f')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## the final data frame","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame({'Label': np.tile(df['Label'],2)})\ndf['img_Path'] = signal_MR+signal_PR+signal_SR\ndf['img_id'] = signal_MR_id+signal_PR_id+signal_SR_id\ndf.groupby(['Label']).count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('data1.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = {'normal': int(0), 'abnormal': int(1)}  \ndf.replace(mapping, inplace=True)\ndf = df.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"droped_normal = df.query('Label == 0').sample(n=150)\ndf.drop(droped_normal.index, inplace=True)\ndf=df.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(['Label']).count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('Scalogram_grayscale_images.csv')\ndroped_normal.to_csv('test_normal.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_folder_path='/kaggle/working/augmented_images/'\nlables_aug=[]\npaths_aug=[]\nid_aug=[]\n# Initialising the ImageDataGenerator class.\n# We will pass in the augmentation parameters in the constructor.\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    brightness_range=(0.8, 1.2)\n)\n\nlabels = ['rotated','sheered', 'zoomed', 'horizontal_flipped' ,'brightness_changed']\n\nfor n in range (len(df.img_Path)):\n    # Loading a sample image \n    img = load_img(df.img_Path[n]) \n    # Converting the input sample image to an array\n    x = img_to_array(img)\n    # Reshaping the input image\n    x = x.reshape((1, ) + x.shape)\n    j=0\n    # Loop through the 5 augmented images and save each image with its corresponding label\n    for i, batch in enumerate(datagen.flow(x, batch_size=1,save_format='png')):\n        # Get the augmented image array\n        augmented_image = batch[0]\n        # Get the corresponding label\n        label = labels[j]\n        j+=1\n        # Save the augmented image with its corresponding label\n        img = array_to_img(augmented_image)\n        img.save(os.path.join(augmented_folder_path, f'{df.img_id[n]}_{label}.png'))\n        paths_aug.append(f'{augmented_folder_path}/{df.img_id[n]}_{label}.png')  \n        lables_aug.append(df.Label[n])\n        id_aug.append(f'{df.img_id[n]}_{label}')\n        if j==5:\n            break  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary from the two lists\ndict = {'img_Path': paths_aug+list(df.img_Path), 'Label': lables_aug+list(df.Label), 'img_id': id_aug+list(df.img_id) }\n\n# Create a new dataframe from the dictionary\nfinal = pd.DataFrame(dict)\n#final=final.sample(frac=1).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.to_csv('Scalogram_grayscale_augumented_images.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.make_archive('/kaggle/working/output', 'zip', '/kaggle/working/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Load CSV Data\ndf_aug = final\n#df_aug = df_aug.drop('Unnamed: 0', axis=1)\n\n# Define image dimensions and batch size\nimg_height = 224\nimg_width = 224\nBATCH_SIZE = 32\n\n# Filter out a specific label and ensure labels are strings\ndf_aug = df_aug[df_aug['Label'] != 'The functional activity of the central and peripheral parts of the retina in both eyes is preserved.'].reset_index(drop=True)\ndf_aug['Label'] = df_aug['Label'].astype(str)\n\n# Generate Image Paths\nimg_Path = []\nfor i in range(len(df_aug.img_id)):\n    if i < 2220:\n        img_Path.append(f'/kaggle/working/augmented_images/{df_aug.img_id[i]}.png')\n    else:\n        img_Path.append(f'/kaggle/working/signals/{df_aug.img_id[i]}.png')\ndf_aug['img_Path'] = img_Path\n\n# Assuming train_df_aug, valid_df_aug, and test_df_aug are already defined\n# Here we create them for completeness\nimage_train, image_test, label_train, label_test = train_test_split(\n    df_aug.img_Path, df_aug.Label, test_size=0.2, random_state=42, stratify=df_aug['Label']\n)\nimage_valid, image_Test, label_valid, label_Test = train_test_split(\n    image_test, label_test, test_size=0.5, random_state=42, stratify=label_test\n)\n\ntrain_df_aug = pd.DataFrame({'image_id': image_train, 'label': label_train}).reset_index(drop=True)\nvalid_df_aug = pd.DataFrame({'image_id': image_valid, 'label': label_valid}).reset_index(drop=True)\ntest_df_aug = pd.DataFrame({'image_id': image_Test, 'label': label_Test}).reset_index(drop=True)\n\n# Create ImageDataGenerator Instances\ntrain_generator = ImageDataGenerator(rescale=1./255.).flow_from_dataframe(\n    dataframe=train_df_aug,\n    directory='/kaggle/working/',  # Ensure this is an empty string since paths are absolute\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_height, img_width),\n    batch_size=BATCH_SIZE,\n    class_mode='binary'  # Change to 'categorical' for multi-class classification\n)\nvalid_generator = ImageDataGenerator(rescale=1./255.).flow_from_dataframe(\n    dataframe=valid_df_aug,\n    directory='/kaggle/working/',  # Ensure this is an empty string since paths are absolute\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_height, img_width),\n    batch_size=BATCH_SIZE,\n    class_mode='binary'  # Change to 'categorical' for multi-class classification\n)\ntest_generator = ImageDataGenerator(rescale=1./255.).flow_from_dataframe(\n    dataframe=test_df_aug,\n    directory='/kaggle/working/',  # Ensure this is an empty string since paths are absolute\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_height, img_width),\n    batch_size=BATCH_SIZE,\n    class_mode='binary'  # Change to 'categorical' for multi-class classification\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, ZeroPadding2D, Conv2D, BatchNormalization, Activation, MaxPooling2D, Add, AveragePooling2D, Flatten, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import BinaryCrossentropy\n\ndef identity_block(X, f, filters, stage, block):\n    # Helper function to implement the identity block\n    # X: input tensor\n    # f: integer, shape of the middle CONV's window for the main path\n    # filters: list of integers, the filters of the 3 CONV layers at the main path\n    # stage: integer, used to name the layers, depending on their position in the network\n    # block: string/character, used to name the layers, depending on their position in the network\n\n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = 'res' + str(stage) + block + '_branch2a', kernel_initializer = 'he_normal')(X)\n    X = BatchNormalization(axis = 3, name = 'bn' + str(stage) + block + '_branch2a')(X)\n    X = Activation('relu')(X)\n    \n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = 'res' + str(stage) + block + '_branch2b', kernel_initializer = 'he_normal')(X)\n    X = BatchNormalization(axis = 3, name = 'bn' + str(stage) + block + '_branch2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = 'res' + str(stage) + block + '_branch2c', kernel_initializer = 'he_normal')(X)\n    X = BatchNormalization(axis = 3, name = 'bn' + str(stage) + block + '_branch2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n\ndef convolutional_block(X, f, filters, stage, block, s = 2):\n    # Helper function to implement the convolutional block\n    # X: input tensor\n    # f: integer, shape of the middle CONV's window for the main path\n    # filters: list of integers, the filters of the 3 CONV layers at the main path\n    # stage: integer, used to name the layers, depending on their position in the network\n    # block: string/character, used to name the layers, depending on their position in the network\n    # s: Integer, specifying the stride to be used\n\n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = 'res' + str(stage) + block + '_branch2a', kernel_initializer = 'he_normal')(X)\n    X = BatchNormalization(axis = 3, name = 'bn' + str(stage) + block + '_branch2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(F2, (f, f), strides = (1,1), padding = 'same', name = 'res' + str(stage) + block + '_branch2b', kernel_initializer = 'he_normal')(X)\n    X = BatchNormalization(axis = 3, name = 'bn' + str(stage) + block + '_branch2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(F3, (1, 1), strides = (1,1), name = 'res' + str(stage) + block + '_branch2c', kernel_initializer = 'he_normal')(X)\n    X = BatchNormalization(axis = 3, name = 'bn' + str(stage) + block + '_branch2c')(X)\n\n    # Shortcut Path\n    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = 'res' + str(stage) + block + '_branch1', kernel_initializer = 'he_normal')(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = 'bn' + str(stage) + block + '_branch1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n\n# Define the model input and initial convolutional layer\ninput_shape = (224, 224, 3)\nX_input = Input(input_shape)\nX = ZeroPadding2D((3, 3))(X_input)\nX = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = 'he_normal')(X)\nX = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\nX = Activation('relu')(X)\nX = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n# Stage 2\nX = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\nX = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\nX = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n# Stage 3-5 (Add more blocks as needed)\n\n# Average Pooling\nX = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n\nclasses = 1\n# Output layer\nX = Flatten()(X)\nX = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = 'he_normal')(X)\n\n# Create model\nmodel = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n# Compile model (Add your optimizer, loss, and metrics)\nmodel.compile(optimizer='adam', loss= BinaryCrossentropy(), metrics=['accuracy'])\n\n# Model summary\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming X_train_images and y_train_categorical are your training data and labels\n# Define other parameters like batch_size, epochs, etc.\n# Fit the model to the training data\nmodel.fit(train_generator, epochs=10,validation_data = valid_generator, verbose = 2 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, balanced_accuracy_score\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.linear_model import LogisticRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_ = model.predict(test_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.round(y_pred_).flatten()\ny_true = np.array(test_df_aug.label,int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\ndisp.plot()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision = precision_score(y_true, y_pred)\nprint(f\"Precision: {precision:.4f}\")\nrecall = recall_score(y_true, y_pred)\nprint(f\"Recall (Sensitivity): {recall:.4f}\")\nf1 = f1_score(y_true, y_pred)\nprint(f\"F1 Score: {f1:.4f}\")\nbalanced_accuracy = balanced_accuracy_score(y_true, y_pred)\nprint(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")\nspecificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\nprint(f\"Specificity: {specificity:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\n\nfpr, tpr, _ = metrics.roc_curve(y_true, y_pred)\n# Create ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='b')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curve')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the entire model to a HDF5 file\nmodel.save('resnet50_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}